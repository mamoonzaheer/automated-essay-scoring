{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b751e8-7c6e-41ad-b7c9-2b1597357c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0455fcc4-7ec4-4ef3-b792-77f9c2a76e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mamoo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mamoo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mamoo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28ac69a-75a8-42de-a61e-bb27551a1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'train.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d925521-4810-4747-a730-14fda952c48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      essay_id                                          full_text  score\n",
      "0      000d118  Many people have car where they live. The thin...      3\n",
      "1      000fe60  I am a scientist at NASA that is discussing th...      3\n",
      "2      001ab80  People always wish they had the same technolog...      4\n",
      "3      001bdc0  We all heard about Venus, the planet without a...      4\n",
      "4      002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3\n",
      "...        ...                                                ...    ...\n",
      "17302  ffd378d  the story \" The Challenge of Exploing Venus \" ...      2\n",
      "17303  ffddf1f  Technology has changed a lot of ways that we l...      4\n",
      "17304  fff016d  If you don't like sitting around all day than ...      2\n",
      "17305  fffb49b  In \"The Challenge of Exporing Venus,\" the auth...      1\n",
      "17306  fffed3e  Venus is worthy place to study but dangerous. ...      2\n",
      "\n",
      "[17307 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c120036-8f2b-4bbe-8c5b-6612c677e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e684a32-5fb2-4ff1-9f5a-ca02278a6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a8ff98-c383-4d60-bf41-86eef8995924",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed_text'] = data['full_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb3816c-b9db-43e8-b94f-0c8f2da3991a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>many people car live thing dont know use car a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>scientist nasa discussing face mar explaining ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>people always wish technology seen movie best ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>heard venus planet without almost oxygen earth...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>dear state senator letter argue favor keeping ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                     processed_text  score\n",
       "0  000d118  many people car live thing dont know use car a...      3\n",
       "1  000fe60  scientist nasa discussing face mar explaining ...      3\n",
       "2  001ab80  people always wish technology seen movie best ...      4\n",
       "3  001bdc0  heard venus planet without almost oxygen earth...      4\n",
       "4  002ba53  dear state senator letter argue favor keeping ...      3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['essay_id', 'processed_text', 'score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf033f3-ffb5-47ce-bf2f-d7837614dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data[['essay_id', 'processed_text', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab7321d-87f5-428f-8311-74190a812b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      essay_id                                     processed_text  score\n",
      "0      000d118  many people car live thing dont know use car a...      3\n",
      "1      000fe60  scientist nasa discussing face mar explaining ...      3\n",
      "2      001ab80  people always wish technology seen movie best ...      4\n",
      "3      001bdc0  heard venus planet without almost oxygen earth...      4\n",
      "4      002ba53  dear state senator letter argue favor keeping ...      3\n",
      "...        ...                                                ...    ...\n",
      "17302  ffd378d  story challenge exploing venus informative pie...      2\n",
      "17303  ffddf1f  technology changed lot way live today nowadays...      4\n",
      "17304  fff016d  dont like sitting around day great opportunity...      2\n",
      "17305  fffb49b  challenge exporing venus author suggests study...      1\n",
      "17306  fffed3e  venus worthy place study dangerous reaosn thei...      2\n",
      "\n",
      "[17307 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f40ce056-0aed-4424-a6e4-42956cec242f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17307, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_representation = tfidf_vectorizer.fit_transform(data['processed_text'])\n",
    "tfidf_representation_dense = tfidf_representation.toarray()\n",
    "print(tfidf_representation_dense.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af64e0a6-2a67-487c-9703-b2e50cf356f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' '100' '11' '114' '118' '12' '13' '14' '147' '15' '156' '16' '17'\n",
      " '170' '18' '1800s' '1888' '19' '1900s' '1940s' '1945' '1947' '1950s'\n",
      " '1960' '1960s' '1968' '1976' '1980s' '1990s' '1992' '1995' '1997' '1998'\n",
      " '20' '200' '2000' '2001' '2001a' '2005' '2006' '2009' '2012' '2012s'\n",
      " '2013' '2015' '2016' '2020' '21' '21st' '22' '22euro' '23' '23rd' '24'\n",
      " '247' '25' '25mph' '266' '27' '270' '271' '28' '29' '2nd' '30' '300'\n",
      " '301' '31' '335' '34' '35' '3687' '370' '38' '39' '3d' '40' '4000'\n",
      " '40000' '41' '41971' '43' '44' '50' '500000' '51' '513' '51998' '533'\n",
      " '538' '55' '5500' '5559' '57' '5th' '60' '617' '67' '70' '797' '80' '800'\n",
      " '82001' '83' '8th' '90' '97' '98' 'abd' 'ability' 'able' 'aboard'\n",
      " 'abolish' 'abolished' 'abolishing' 'absolute' 'absolutely' 'absolutly'\n",
      " 'absurd' 'abundance' 'abundant' 'abuse' 'academic' 'accelerate'\n",
      " 'accelerating' 'accept' 'accepted' 'access' 'accessible' 'accident'\n",
      " 'accidently' 'accomplish' 'accomplished' 'accomplishment' 'according'\n",
      " 'accordingly' 'account' 'accountable' 'accuracy' 'accurate' 'accurately'\n",
      " 'accusation' 'accustomed' 'achieve' 'achieved' 'achievement' 'acid'\n",
      " 'acient' 'acknowledge' 'acording']\n"
     ]
    }
   ],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(tfidf_feature_names[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac83ee-84f6-4e42-a6f6-ad8ca031c2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
